Input:
Given the following output from git diff, write a commit message:

@@ -313,6 +313,14 @@ function biuldCocoaAsyncSocket(checkoutDir, buildDir, buildWithTests) {
buildDir, 'Release' + '-' + sdk, projectName + '.framework');
return fs.copy(frameworkBuildDir, frameworkOutputDir, { clobber: false });
+ })
+ .then(function () {
+ var frameworkBuildDir = path.join(
+ buildDir, projectConfiguration + '-' + sdk, projectName + '.framework');
+ var thaliCoreFrameworkOutputDir = path.join(
+ checkoutDir, '..', '..', projectName + '.framework');
+
+ return fs.copy(frameworkBuildDir, thaliCoreFrameworkOutputDir, { clobber: false });
});
}
@@ -320,6 +328,7 @@ function biuldSwiftXCTest(checkoutDir, buildDir, buildWithTests) {
var projectDir = 'swift-corelibs-xctest';
var projectName = 'XCTest'
var projectScheme = 'SwiftXCTest-iOS';
+ var frameworkName = 'SwiftXCTest';
var projectConfiguration = 'Release';
var sdk = 'iphoneos';
@@ -343,6 +352,17 @@ function biuldSwiftXCTest(checkoutDir, buildDir, buildWithTests) {
.then(function () {
return fs.ensureDir(buildDir);
})
+ .then(function () {
+ var frameworkBuildDir = path.join(
+ buildDir, projectConfiguration + '-' + sdk, frameworkName + '.framework');
+ var thaliCoreFrameworkOutputDir = path.join(
+ checkoutDir, '..', '..', frameworkName + '.framework');
+
+ console.log('from: ', frameworkBuildDir);
+ console.log('to : ', thaliCoreFrameworkOutputDir);
+
+ return fs.copy(frameworkBuildDir, thaliCoreFrameworkOutputDir, { clobber: false });
+ });
}
/**


Output:
Added code to copy framework files to the output directory for biuldCocoaAsyncSocket and biuldSwiftXCTest functions.

Original:
Add phase that copies frameworks into iOS infrustructure dir to be able to build ThaliTest app.

-------------------------------------------

Input:
Given the following output from git diff, write a commit message:

@@ -41,6 +41,7 @@ import PropTypes from 'prop-types';
import NotificationsIOS from 'react-native-notifications';
import InAppNotification from 'react-native-in-app-notification';
import FCM, { FCMEvent } from 'react-native-fcm';
+import { REHYDRATE } from 'redux-persist';
import { registerConfig } from 'lib/utils/config';
import {
@@ -177,6 +178,9 @@ class AppWithNavigationState extends React.PureComponent<Props> {
initialAndroidNotifHandled = false;
componentDidMount() {
+ if (__DEV__ && Platform.OS === "android") {
+ this.props.dispatchActionPayload(REHYDRATE, null);
+ }
NativeAppState.addEventListener('change', this.handleAppStateChange);
this.handleInitialURL();
Linking.addEventListener('url', this.handleURLChange);


Output:
Add logic to rehydrate redux store on Android in development mode.

Original:
Call redux-persist REHYDRATE ourselves in __DEV__ on Android

For some reason it doesn't fire when I refresh the app source in the Android emulator, so we need to manually fire it.

-------------------------------------------

Input:
Given the following output from git diff, write a commit message:

@@ -118,7 +118,7 @@ export default defineMessages({
traffic: 'Traffic',
type: 'Type',
unknown: 'Unknown',
- updatedAt: 'Updated at',
+ updatedAt: 'Last updated at',
uplinksReceived: 'Uplinks Received',
user: 'User',
userId: 'User ID',


Output:
Update label for last updated time in the UI

Original:
console: Change updatedAt message

-------------------------------------------

Input:
Given the following output from git diff, write a commit message:

@@ -167,6 +167,7 @@ if scdoc.found()
'waybar-cpu.5.scd',
'waybar-custom.5.scd',
'waybar-idle-inhibitor.5.scd',
+ 'waybar-memory.5.scd',
]
foreach filename : man_files


Output:
Added waybar-memory.5.scd to the list of man files in the foreach loop.

Original:
Add waybar-memory(5)

-------------------------------------------

Input:
Given the following output from git diff, write a commit message:

@@ -97,7 +97,7 @@ module.exports = function (config) {
reporters: [
{ type: 'html', dir: 'coverage/' },
{ type: 'text-summary' },
- { type: 'lcov', subdir: 'lcov-report' }
+ { type: 'lcov', subdir: '/' }
],
},
reporters: reporters,


Output:
Update lcov reporter configuration in karma config

Original:
Fix lcov.info file path for NPM coverage script

-------------------------------------------

Input:
Given the following output from git diff, write a commit message:

@@ -4508,7 +4508,7 @@ usePreliminaryContext : false}}">\
}, {
data : {
__metadata : {
- uri : "/SalesOrderLineItemSet(SalesOrderID='1',ItemPosition='10~1~')"
+ uri : "/SalesOrderLineItemSet(SalesOrderID='1',ItemPosition='10')"
},
ItemPosition : "10",
Note : "foo",
@@ -4517,11 +4517,11 @@ usePreliminaryContext : false}}">\
statusCode : 201
}, {
location : "/sap/opu/odata/IWBEP/GWSAMPLE_BASIC/SalesOrderLineItemSet"
- + "(SalesOrderID='1',ItemPosition='10~1~')",
+ + "(SalesOrderID='1',ItemPosition='10')",
"sap-message" : getMessageHeader(oNoteError)
})
.expectMessage(oNoteError,
- "/SalesOrderLineItemSet(SalesOrderID='1',ItemPosition='10~1~')/");
+ "/SalesOrderLineItemSet(SalesOrderID='1',ItemPosition='10')/");
// code under test
that.oView.byId("page").setBindingContext(
@@ -4545,8 +4545,6 @@ usePreliminaryContext : false}}">\
QUnit.test("createEntry: update deep path with resulting entity (deep)", function (assert) {
var oModel = createSalesOrdersModel({refreshAfterChange : false, useBatch : true}),
oNoteError = this.createResponseMessage("Note"),
- oNoteErrorCopy = cloneODataMessage(oNoteError,
- "(SalesOrderID='1',ItemPosition='10~0~')/Note"),
sView = '\
<FlexBox binding="{path : \'/SalesOrderSet(\\\'1\\\')\',\
parameters : {select : \'SalesOrderID,Note\', expand : \'ToLineItems\'}}">\
@@ -4574,6 +4572,9 @@ usePreliminaryContext : false}}">\
.expectChange("noteSalesOrder", "foo");
return this.createView(assert, sView, oModel).then(function () {
+ var oNoteErrorCopy = cloneODataMessage(oNoteError,
+ "(SalesOrderID='1',ItemPosition='10')/Note");
+
that.expectRequest({
created : true,
data : {
@@ -4587,7 +4588,7 @@ usePreliminaryContext : false}}">\
}, {
data : {
__metadata : {
- uri : "/SalesOrderLineItemSet(SalesOrderID='1',ItemPosition='10~0~')"
+ uri : "/SalesOrderLineItemSet(SalesOrderID='1',ItemPosition='10')"
},
ItemPosition : "10~0~",
Note : "bar",
@@ -4596,7 +4597,7 @@ usePreliminaryContext : false}}">\
statusCode : 201
}, {
location : "/sap/opu/odata/IWBEP/GWSAMPLE_BASIC/SalesOrderSet('1')/ToLineItems"
- + "(SalesOrderID='1',ItemPosition='10~0~')",
+ + "(SalesOrderID='1',ItemPosition='10')",
"sap-message" : getMessageHeader(oNoteError)
})
.expectMessage(oNoteErrorCopy, "/SalesOrderLineItemSet",
@@ -4623,11 +4624,9 @@ usePreliminaryContext : false}}">\
// the same as the fullTarget of associated messages.
// BCP: 002028376600002197422020
QUnit.test("createEntry: no change of deep path for non-collections", function (assert) {
- var oCompanyNameError = this.createResponseMessage("CompanyName"),
- oModel = createSalesOrdersModel({useBatch : true}),
+ var oModel = createSalesOrdersModel({useBatch : true}),
sView = '\
<FlexBox binding="{/SalesOrderSet(\'1\')}" id="page">\
- <Input id="note" value="{Note}" />\
<FlexBox id="details">\
<Input id="name" value="{CompanyName}" />\
</FlexBox>\
@@ -4637,13 +4636,14 @@ usePreliminaryContext : false}}">\
this.expectHeadRequest()
.expectRequest("SalesOrderSet('1')", {
__metadata : {uri : "SalesOrderSet('1')"},
- Note : "foo",
SalesOrderID : "1"
})
- .expectChange("note", null)
- .expectChange("note", "foo");
+ .expectChange("name", null)
+ .expectChange("name", undefined);
return this.createView(assert, sView, oModel).then(function () {
+ var oCompanyNameError = that.createResponseMessage("CompanyName");
+
that.expectRequest({
created : true,
data : {
@@ -4657,28 +4657,30 @@ usePreliminaryContext : false}}">\
}, {
data : {
__metadata : {
- uri : "/Product('BP1')"
+ uri : "/BusinessPartnerSet('BP1')"
},
- CompanyName : "SAP",
- ProductID : "BP1"
+ BusinessPartnerID : "BP1",
+ CompanyName : "SAP"
},
statusCode : 201
}, {
- location : "/sap/opu/odata/IWBEP/GWSAMPLE_BASIC/SalesOrderSet('1')"
- + "/ToBusinessPartner",
+ location : "/sap/opu/odata/IWBEP/GWSAMPLE_BASIC/BusinessPartnerSet('BP1')",
"sap-message" : getMessageHeader(oCompanyNameError)
})
- .expectMessage(oCompanyNameError, "/SalesOrderSet('1')/ToBusinessPartner/");
+ .expectChange("name", "SAP")
+ .expectMessage(oCompanyNameError, "/BusinessPartnerSet('BP1')/",
+ "/SalesOrderSet('1')/ToBusinessPartner/");
// code under test
that.oView.byId("details").setBindingContext(
- oModel.createEntry("/SalesOrderSet('1')/ToBusinessPartner", {properties : {}})
+ oModel.createEntry("ToBusinessPartner", {
+ context : that.oView.byId("page").getBindingContext(),
+ properties : {}
+ })
);
oModel.submitChanges();
return that.waitForChanges(assert);
- }).then(function () {
- assert.strictEqual(that.oView.byId("name").getValue(), "SAP");
});
});


Output:
Update SalesOrderLineItemSet(SalesOrderID='1',ItemPosition='10~1~') to SalesOrderLineItemSet(SalesOrderID='1',ItemPosition='10') in createEntry method.

Original:
[INTERNAL] sap.ui.model.odata.v2.ODataModel: update tests for createEntry fullTarget calculation

PS1: late comments from 4852724

Change-Id: Ie09cafca97192ef93e0733c3f739c0d4db940ea5

-------------------------------------------

Input:
Given the following output from git diff, write a commit message:

@@ -63,7 +63,6 @@ def verify_rules_file(rule_file_path, sigma_config, sigma_backend):
true: rule_file_path contains a valid sigma rule
false: rule_file_path does not contain a valid sigma rule
"""
-
logger.debug('[sigma] Reading rules from {0:s}'.format(
rule_file_path))
@@ -76,7 +75,7 @@ def verify_rules_file(rule_file_path, sigma_config, sigma_backend):
parser = sigma_collection.SigmaCollectionParser(
rule_file_content, sigma_config, None)
parsed_sigma_rules = parser.generate(sigma_backend)
- except (NotImplementedError):
+ except NotImplementedError:
logger.error('{0:s} Error with file {1:s}'
.format(rule_filename, rule_file_path), exc_info=True)
return False
@@ -86,7 +85,7 @@ def verify_rules_file(rule_file_path, sigma_config, sigma_backend):
'you should not use this rule in Timesketch '
.format(rule_filename, rule_file_path), exc_info=True)
return False
- except (FileNotFoundError) as e:
+ except FileNotFoundError:
logger.error('Rule file not found')
return False
@@ -109,7 +108,6 @@ def run_verifier(rules_path, config_file_path):
- sigma_verified_rules with rules that can be added
- sigma_rules_with_problems with rules that should not be added
"""
-
if not os.path.isdir(rules_path):
raise IOError('Rules not found at path: {0:s}'.format(
rules_path))


Output:
Fixed bug in verify_rules_file function and added exception handling.

Original:
remove empty line after function docstring

-------------------------------------------

Input:
Given the following output from git diff, write a commit message:

@@ -233,7 +233,7 @@ def test_mtgnn():
layers=layers, propalpha=propalpha, tanhalpha=tanhalpha, layer_norm_affline=True)
xd = 8
FE = torch.rand(num_nodes, xd)
- model_with_feat = MTGNN(gcn_true=gcn_true, build_adj=build_adj, gcn_depth=gcn_depth, num_nodes=num_nodes,
+ model2 = MTGNN(gcn_true=gcn_true, build_adj=build_adj, gcn_depth=gcn_depth, num_nodes=num_nodes,
kernel_size=kernel_size, kernel_set=kernel_set, dropout=dropout, subgraph_size=subgraph_size,
node_dim=node_dim, dilation_exponential=dilation_exponential,
conv_channels=conv_channels, residual_channels=residual_channels,
@@ -261,14 +261,16 @@ def test_mtgnn():
output = model(tx, A_tilde, idx=id)
output = output.transpose(1, 3)
assert output.shape == (batch_size, 1, num_nodes, seq_out_len)
- output_with_feat = model_with_feat(tx, A_tilde, idx=id, FE=FE)
- output_with_feat = output_with_feat.transpose(1, 3)
- assert output_with_feat.shape == (batch_size, 1, num_nodes, seq_out_len)
+ output2 = model2(tx, A_tilde, idx=id, FE=FE)
+ output2 = output2.transpose(1, 3)
+ assert output2.shape == (batch_size, 1, num_nodes, seq_out_len)
output3 = model3(tx, A_tilde, FE=FE)
output3 = output3.transpose(1, 3)
assert output3.shape == (batch_size, 1, num_nodes, seq_out_len)
seq_in_len = 24
+ seq_out_len = 5
+ build_adj = False
x_all = 2 * torch.rand(batch_size, seq_in_len, num_nodes, in_dim) - 1
model = MTGNN(gcn_true=gcn_true, build_adj=build_adj, gcn_depth=gcn_depth, num_nodes=num_nodes,
kernel_size=kernel_size, kernel_set=kernel_set, dropout=dropout, subgraph_size=subgraph_size,
@@ -277,6 +279,14 @@ def test_mtgnn():
skip_channels=skip_channels, end_channels=end_channels,
seq_length=seq_in_len, in_dim=in_dim, out_dim=seq_out_len,
layers=layers, propalpha=propalpha, tanhalpha=tanhalpha, layer_norm_affline=False)
+ dilation_exponential = 2
+ model2 = MTGNN(gcn_true=gcn_true, build_adj=build_adj, gcn_depth=gcn_depth, num_nodes=num_nodes,
+ kernel_size=kernel_size, kernel_set=kernel_set, dropout=dropout, subgraph_size=subgraph_size,
+ node_dim=node_dim, dilation_exponential=dilation_exponential,
+ conv_channels=conv_channels, residual_channels=residual_channels,
+ skip_channels=skip_channels, end_channels=end_channels,
+ seq_length=seq_in_len, in_dim=in_dim, out_dim=seq_out_len,
+ layers=layers, propalpha=propalpha, tanhalpha=tanhalpha, layer_norm_affline=True, xd=xd)
trainx = torch.Tensor(x_all).to(device)
trainx= trainx.transpose(1, 3)
for j in range(num_split):
@@ -288,6 +298,9 @@ def test_mtgnn():
output = model(tx, A_tilde, idx=id)
output = output.transpose(1, 3)
assert output.shape == (batch_size, 1, num_nodes, seq_out_len)
+ output2 = model2(tx, A_tilde, idx=id, FE=FE)
+ output2 = output2.transpose(1, 3)
+ assert output2.shape == (batch_size, 1, num_nodes, seq_out_len)
def test_gman():
"""


Output:
Added new model "model2" with different dilation exponential value and layer_norm_affline parameter set to True. Fixed assertion for output2.shape.

Original:
MTGNN coverage 97%->98%

-------------------------------------------

Input:
Given the following output from git diff, write a commit message:

@@ -27,8 +27,8 @@ with an image downloaded from the [official 64bit repository](https://downloads.
In order to run a baking instance, you'll need the following Tezos binaries:
`tezos-client`, `tezos-node`, `tezos-baker-<proto>`, `tezos-endorser-<proto>`.
-The currently supported protocols are `008-PtEdo2Zk` (used on `mainnet` and `edo2net`)
-and `009-PsFLoren` (used on `florencenet`).
+The currently supported protocols are `008-PtEdo2Zk` (used on `edo2net`)
+and `009-PsFLoren` (used on `florencenet` and `mainnet`).
Also, note that the corresponding packages have protocol
suffix in lowercase, e.g. the list of available baker packages can be found
[here](https://launchpad.net/~serokell/+archive/ubuntu/tezos/+packages?field.name_filter=tezos-baker&field.status_filter=published).


Output:
Updated list of currently supported protocols and their usage on specific networks

Original:
update text to reflect that mainnet is now using florence protocol

-------------------------------------------

Input:
Given the following output from git diff, write a commit message:

@@ -247,7 +247,7 @@ type CreatePendingThreadArgs = {
+viewerID: string,
+threadType: ThreadType,
+members?: $ReadOnlyArray<GlobalAccountUserInfo | UserInfo>,
- +parentThreadID?: ?string,
+ +parentThreadInfo?: ?ThreadInfo,
+threadColor?: ?string,
+name?: ?string,
+sourceMessageID?: string,
@@ -257,7 +257,7 @@ function createPendingThread({
viewerID,
threadType,
members,
- parentThreadID,
+ parentThreadInfo,
threadColor,
name,
sourceMessageID,
@@ -294,7 +294,7 @@ function createPendingThread({
description: null,
color: threadColor ?? generatePendingThreadColor(memberIDs),
creationTime: now,
- parentThreadID: parentThreadID ?? null,
+ parentThreadID: parentThreadInfo?.id ?? null,
members: [
{
id: viewerID,
@@ -362,11 +362,7 @@ function createPendingSidebar(
viewerID: string,
markdownRules: ParserRules,
): ThreadInfo {
- const {
- id: parentThreadID,
- color,
- type: parentThreadType,
- } = parentThreadInfo;
+ const { color, type: parentThreadType } = parentThreadInfo;
const messageTitle = getMessageTitle(
sourceMessageInfo,
@@ -412,7 +408,7 @@ function createPendingSidebar(
viewerID,
threadType: threadTypes.SIDEBAR,
members: [...initialMembers.values()],
- parentThreadID,
+ parentThreadInfo,
threadColor: color,
name: threadName,
sourceMessageID: sourceMessageInfo.id,


Output:
Refactor createPendingThread and createPendingSidebar functions to use parentThreadInfo instead of parentThreadID

Original:
[lib] Pass whole parentThreadInfo to CreatePendingThreadArgs

Summary: This will be necessary in a following diff.

Test Plan: Flow

Reviewers: palys-swm

Reviewed By: palys-swm

Subscribers: Adrian, atul, karol-bisztyga

Differential Revision: https://phabricator.ashoat.com/D1995

-------------------------------------------

